<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Playing Fasttracker 2 .XM files in Javascript &#8211; a1k0n.net</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="Andy Sloane">
    <meta name="keywords" content="">
    <link rel="canonical" href="http://www.a1k0n.net/2015/11/09/javascript-ft2-player.html">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for a1k0n.net" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?201511101055" type="text/css">

    <!-- Fonts -->
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    

    <!-- Verifications -->
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Playing Fasttracker 2 .XM files in Javascript">
    <meta property="og:description" content="">
    <meta property="og:url" content="http://www.a1k0n.net/2015/11/09/javascript-ft2-player.html">
    <meta property="og:site_name" content="a1k0n.net">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
    <meta name="twitter:title" content="Playing Fasttracker 2 .XM files in Javascript" />
    <meta name="twitter:description" content="" />
    <meta name="twitter:url" content="http://www.a1k0n.net/2015/11/09/javascript-ft2-player.html" />

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-24584703-1']);
      _gaq.push(['_trackPageview']);
      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    
<script src="/code/jsxm/xm.js"></script>
<script src="/code/jsxm/xmeffects.js"></script>
<script src="http://a1k0n-pub.s3-website-us-west-1.amazonaws.com/xm/xmlist.js"></script>
<style>

.centered {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

#filelist a { color: #fff; }

.playercontainer {
  background:#000;
}

.hscroll {
  overflow: auto;
  margin-bottom: 14px;
}

.hscroll::-webkit-scrollbar {
    -webkit-appearance: none;
}

.hscroll::-webkit-scrollbar:horizontal {
    height: 11px;
}

.hscroll::-webkit-scrollbar-thumb {
    border-radius: 2px;
    border: 1px solid #93C3E9; /* should match background, can't be transparent */
    background-color: #A0D4FD;
}

.hscroll::-webkit-scrollbar-track { 
    background-color: #333; 
    border-radius: 8px; 
} 

</style>

</head>

<body class="site">

	

  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="/" class="site-title">a1k0n.net</a>
      <nav class="site-nav">
        <a href="/about.html">About</a>

      </nav>
      <div class="clearfix"></div>
      
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        <div class="post-header mb2">
  <h1>Playing Fasttracker 2 .XM files in Javascript</h1>
  <span class="post-meta">Nov 9, 2015</span><br>
  
</div>

<article class="post-content">
  <div class="playercontainer">
  <div> <canvas class="centered" id="title" width="640" height="22"></canvas> </div>
  <div class="hscroll">
   <div> <canvas class="centered" id="vu" width="224" height="64"></canvas> </div>
   <div> <canvas class="centered" id="gfxpattern" width="640" height="200"></canvas> </div>
  </div>
  <div id="instruments"></div>
  <div>
    <p style="text-align: center">
      <button id="playpause" disabled="true" style="width: 100px">Play</button>
      <button id="loadbutton" style="width: 100px">Load</button>
    </p>
  </div>
  <div style="display: none" id="filelist"></div>
</div>

<h2 id="what-is-this-thing">What is this thing?</h2>

<p>Hit the play button above and it will play music; specifically, music composed
with (or at least, compatible with) a program released in 1994 called
FastTracker 2; this is a Javascript homage I wrote in a fit of nostalgia. The
<a href="https://github.com/a1k0n/jsxm/">source code is on GitHub</a> if you’d like to
check it out.</p>

<p>FastTracker 2 looks like this:</p>

<p><img src="/img/ft2.png" alt="FastTracker II screenshot" /></p>

<p>I using the original font to render a pastiche of the FT2 interface above.</p>

<h2 id="xm-files">.XM files</h2>

<p>The ubiquitous .MOD music file format originated on the Commodore Amiga in the
late 80s. It was more or less designed around the “Paula” chip inside the Amiga
which plays four 8-bit PCM channels simultaneously. It is fairly amazing what
artists are able to accomplish in just four voices; I’ve converted a few of
Lizardking’s old four-channel .MODs to .XM format so they can be played in the
player above; try them out with the load button above.</p>

<p>FastTracker 2’s .XM (eXtended Module) format was created as a multi-channel
extension to .MOD in the 90s; it was written by PC demo group
<a href="http://www.pouet.net/groups.php?which=161">Triton</a>. There were other
contemporaneous multi-channel MOD-type music trackers, like ScreamTracker 3’s
.S3M and later Impulse Tracker’s .IT. Nearly all PC demos and many games in the
90s and early 2000s played music in one of these formats.</p>

<p>Underneath the hood, it’s several (14 in the case of the default song that
comes up here) <em>channels</em> independently playing <em>samples</em> at various
pitches and volume levels, controlled by the <em>pattern</em> which is what you
see scrolling above.</p>

<p>Patterns are a lot like assembly language for playing music, complete with a
slew of hexadecimal numbers and opaque syntax, except they are laid out like a
spreadsheet rather than a single column of instructions. Each cell contains
notations for playing or releasing a note with a certain instrument, optionally
modifying the volume, panning, or pitch with <em>effects</em>.</p>

<p>Every sound that is played is one of the <em>samples</em>, shown at the top of this
page as little waveforms and numbers in the table below the pattern. The idea
is that the musician would record an instrument, like a piano or a bass, at a
certain note, and then we play them back at higher or lower speeds to change
the pitch.</p>

<p>Theoretically each sample has a name like “piano” or “bass”, but in practice,
musicians tended to erase those and write messages instead. Later trackers
would add a song message field to avoid abuse of the instrument list.</p>

<p><img src="/img/ft2pattern.png" alt="Annotated pattern image" /></p>

<p>In the above example, we are about to play an E note in octave 5 with
instrument number 2 on the first channel, and in the second channel we play the
same note an octave higher with the same instrument, except we also lower the
volume to 0x2C (maximum volume is 0x40, so this is between a half and 3/4ths
full volume). The second channel is also going to play with effect 0, which is
an arpeggio, switching between 0, 0x0c or 12, and 0 semitones higher – meaning
it’s going to rapidly play a sequence of E-6, E-7, E-6, and repeat.</p>

<p>Tracker programs don’t have any knowledge of the musical scale, so they always
render accidentals as sharps, e.g. C#4 instead of Db4.</p>

<p>XM <em>instruments</em> go beyond .MOD samples in that they include volume and panning
envelopes, and can have multiple different samples per instrument – so you
could record various piano notes and use a recording closest to the note you’re
playing rather than stretching a sample several octaves, which sounds bad. I
only render the first sample per instrument in the table above though.</p>

<p>In .MOD-derived formats, each row of pattern data is played at a certain rate
controlled by the <em>speed</em> and <em>BPM</em> which have a sort of tangential
relationship to the terms you may be familiar with. <em>speed</em> controls the row
speed in <em>ticks</em>, and <em>BPM</em> controls how long <em>ticks</em> are.  A <em>tick</em> is defined
as 2500/<em>BPM</em> milliseconds.</p>

<p>Typical values are <em>BPM</em>=125 and <em>speed</em>=6, corresponding to 2500/125 = 20ms
per tick, or 50 ticks/second; and 50/6 = 8.333 rows per second. If we assume
the downbeat happens every four rows then it works out to 125 beats per minute.
But if <em>speed</em> is 5 then it’s 150 beats per minute, so we can’t really take the
terms at face value.</p>

<p>Each <em>tick</em> we process <em>effects</em> – modifications to the volume or pitch of a
note. Effects are represented by three hexadecimal digits: the effect type
(first digit) and parameter (second two digits). In XM the effect type goes
beyond the hex digits and goes all the way from 0-9 and A-Z.</p>

<p>Examples include arpeggio (switching between three notes really fast; effect
047 plays a major chord), portamento (sliding from one note to another, like a
trombone does; effect 1xx slides up 2xx down, and 3xx to a specific note),
vibrato (vibrating the pitch up and down; 4xx), or ramping the volume up or
down (Axy). If you watch closely while the song is playing you can try to work
it out.</p>

<p>The intracacies of how effects work – some affect the song playing as a whole,
some happen only on the first tick of a row, some only on every tick <em>except</em>
the first one in a row – could be its own long and not very interesting
article, so I’ll leave out the details. There are decent but mutually
contradictory resources online.</p>

<h2 id="real-time-audio-synthesis-in-javascript">Real-time Audio Synthesis in Javascript</h2>

<p>The <code>webkitAudioContext</code> element was introduced to HTML a while back, and is
now available in the standard as <code>AudioContext</code>. The API is fairly flexible, and
one of the things you can do with it is get a Javascript callback which writes
samples more or less directly to the output device, just like we used to do
with DMA loop interrupts back in the day. It’s called <code>createScriptProcessor</code>.</p>

<p>You can be up and running making all kinds of noise in a jiffy:</p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kd">function</span> <span class="nx">InitAudio</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// Create an AudioContext, falling back to </span>
  <span class="c1">// webkitAudioContext (e.g., for Safari)</span>
  <span class="kd">var</span> <span class="nx">audioContext</span> <span class="o">=</span> <span class="nb">window</span><span class="p">.</span><span class="nx">AudioContext</span> <span class="o">||</span> <span class="nb">window</span><span class="p">.</span><span class="nx">webkitAudioContext</span><span class="p">;</span>
  <span class="kd">var</span> <span class="nx">audioctx</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">audioContext</span><span class="p">();</span>

  <span class="c1">// Create a &quot;gain node&quot; which will just multiply everything input</span>
  <span class="c1">//  to it by some constant; this gives us a volume control.</span>
  <span class="nx">gainNode</span> <span class="o">=</span> <span class="nx">audioctx</span><span class="p">.</span><span class="nx">createGain</span><span class="p">();</span>
  <span class="nx">gainNode</span><span class="p">.</span><span class="nx">gain</span><span class="p">.</span><span class="nx">value</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span>  <span class="c1">// master volume</span>

  <span class="c1">// Create a script processor node with 0 input channels,</span>
  <span class="c1">// 2 output channels, and a 4096-sample buffer size</span>
  <span class="nx">jsNode</span> <span class="o">=</span> <span class="nx">audioctx</span><span class="p">.</span><span class="nx">createScriptProcessor</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
  <span class="nx">jsNode</span><span class="p">.</span><span class="nx">onaudioprocess</span> <span class="o">=</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="nx">buflen</span> <span class="o">=</span> <span class="nx">e</span><span class="p">.</span><span class="nx">outputBuffer</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span>
    <span class="kd">var</span> <span class="nx">dataL</span> <span class="o">=</span> <span class="nx">e</span><span class="p">.</span><span class="nx">outputBuffer</span><span class="p">.</span><span class="nx">getChannelData</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="kd">var</span> <span class="nx">dataR</span> <span class="o">=</span> <span class="nx">e</span><span class="p">.</span><span class="nx">outputBuffer</span><span class="p">.</span><span class="nx">getChannelData</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="c1">// dataL and dataR are Float32Arrays; fill them with</span>
    <span class="c1">// samples, and the framework will play them!</span>
  <span class="p">};</span>

  <span class="c1">// Now, form a pipeline where our script feeds samples to the</span>
  <span class="c1">// gain node, and the gain node writes samples to the</span>
  <span class="c1">// &quot;destination&quot; which actually makes noise.</span>
  <span class="nx">jsNode</span><span class="p">.</span><span class="nx">connect</span><span class="p">(</span><span class="nx">gainNode</span><span class="p">);</span>
  <span class="nx">gainNode</span><span class="p">.</span><span class="nx">connect</span><span class="p">(</span><span class="nx">audioctx</span><span class="p">.</span><span class="nx">destination</span><span class="p">);</span>
<span class="p">}</span></code></pre></div>

<p>Your <code>onaudioprocess</code> function will be called back whenever new samples are
needed to fill the output buffer. With a default samplerate of 44.1kHz, a
4096-sample buffer will expire, and thus your callback will be called, every
~92 milliseconds.</p>

<p>Our goal is to fill this buffer up with the sum of each channel’s output
waveform. Each channel outputs a sample playing at a certain frequency and at a
certain volume. And during a tick, the sample frequency and volume is
constant<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>.  Between ticks, we recompute the channel frequencies, volumes and
envelopes; and on ticks which are even multiples of the current <em>speed</em> value
(3 in the example below), we read a new row of pattern data – notes,
instruments, effects, etc.</p>

<p>The output is just the sum of the individual channels<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> for each sample.
<img src="/img/mod-outputsum.png" alt="Output summed up per tick" /></p>

<p>When we’re done, the output will be laid out something like this:
<img src="/img/mod-audiobuf.png" alt="Audio buffer layout diagram" /></p>

<p>In this example, a tick is 20ms and our output is playing at 44.1kHz, so a tick
is 882 samples. Of course, ticks don’t evenly divide sample buffers, and the
<code>AudioContext</code> specification requires you to use buffer sizes which are powers
of two and ≥ 1024. So when we render samples to our buffer, we may have to
play a partial tick at the beginning and end.</p>

<p>So in our audio callback, we figure out how many samples are in a tick, and fit
them into the output buffer, and add up each channel’s data within a tick. It
looks like this<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup>:</p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kd">var</span> <span class="nx">cur_ticksamp</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>  <span class="c1">// Sample index in current tick</span>
<span class="kd">var</span> <span class="nx">channels</span> <span class="o">=</span> <span class="p">[</span> <span class="p">...</span> <span class="p">];</span>  <span class="c1">// Channel state: sample num, offset, freq, etc</span>

<span class="kd">function</span> <span class="nx">audioCallback</span><span class="p">(</span><span class="nx">e</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">buf_remaining</span> <span class="o">=</span> <span class="nx">e</span><span class="p">.</span><span class="nx">outputBuffer</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span>
  <span class="kd">var</span> <span class="nx">dataL</span> <span class="o">=</span> <span class="nx">e</span><span class="p">.</span><span class="nx">outputBuffer</span><span class="p">.</span><span class="nx">getChannelData</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
  <span class="kd">var</span> <span class="nx">dataR</span> <span class="o">=</span> <span class="nx">e</span><span class="p">.</span><span class="nx">outputBuffer</span><span class="p">.</span><span class="nx">getChannelData</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

  <span class="nx">dataL</span><span class="p">.</span><span class="nx">fill</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>  <span class="c1">// (see footnote 3)</span>
  <span class="nx">dataR</span><span class="p">.</span><span class="nx">fill</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

  <span class="kd">var</span> <span class="nx">f_smp</span> <span class="o">=</span> <span class="nx">audioctx</span><span class="p">.</span><span class="nx">sampleRate</span><span class="p">;</span>  <span class="c1">// our output sample rate</span>
  <span class="kd">var</span> <span class="nx">ticklen</span> <span class="o">=</span> <span class="mi">0</span><span class="o">|</span><span class="p">(</span><span class="nx">f_smp</span> <span class="o">*</span> <span class="mf">2.5</span> <span class="o">/</span> <span class="nx">xm</span><span class="p">.</span><span class="nx">bpm</span><span class="p">);</span>  <span class="c1">// # samples per tick</span>
  <span class="kd">var</span> <span class="nx">offset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">while</span><span class="p">(</span><span class="nx">buf_remaining</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// tickduration is the number of samples we can produce for this</span>
    <span class="c1">// tick; either we finish the tick, or we run out of space at the</span>
    <span class="c1">// end of the buffer</span>
    <span class="kd">var</span> <span class="nx">tickduration</span> <span class="o">=</span> <span class="nb">Math</span><span class="p">.</span><span class="nx">min</span><span class="p">(</span><span class="nx">buf_remaining</span><span class="p">,</span> <span class="nx">ticklen</span> <span class="o">-</span> <span class="nx">cur_ticksamp</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="nx">cur_ticksamp</span> <span class="o">&gt;=</span> <span class="nx">ticklen</span><span class="p">)</span> <span class="p">{</span>
      <span class="c1">// Update our channel structures with new song data</span>
      <span class="nx">nextTick</span><span class="p">();</span>
      <span class="nx">cur_ticksamp</span> <span class="o">-=</span> <span class="nx">ticklen</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">j</span> <span class="o">&lt;</span> <span class="nx">xm</span><span class="p">.</span><span class="nx">num_channels</span><span class="p">;</span> <span class="nx">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="c1">// Add this channel&#39;s samples into the dataL/dataR buffers</span>
      <span class="c1">// starting at &lt;offset&gt; and spanning &lt;tickduration&gt; samples</span>
      <span class="nx">mixChannelInfoBuf</span><span class="p">(</span><span class="nx">channels</span><span class="p">[</span><span class="nx">j</span><span class="p">],</span> <span class="nx">offset</span><span class="p">,</span> <span class="nx">offset</span> <span class="o">+</span> <span class="nx">tickduration</span><span class="p">,</span>
                        <span class="nx">dataL</span><span class="p">,</span> <span class="nx">dataR</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="nx">offset</span> <span class="o">+=</span> <span class="nx">tickduration</span><span class="p">;</span>
    <span class="nx">cur_ticksamp</span> <span class="o">+=</span> <span class="nx">tickduration</span><span class="p">;</span>
    <span class="nx">buf_remaining</span> <span class="o">-=</span> <span class="nx">tickduration</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></div>

<h2 id="note-frequencies">Note frequencies</h2>

<p>In .MOD derivatives, notes at C-4 (that is, a C on octave 4) are played at a
samplerate of 8363Hz. Everything is relative to that; an octave higher, for
instance, would be 16726Hz – twice the frequency. For each semitone up, we
effectively multiply the frequency by the twelfth root of two. In general, the
frequency can be computed by <code>8363 * Math.pow(2, (note - 48) / 12.0)</code>. <code>note</code>
here is the note number in semitones, starting at 0 for C-0 and going up to 95
for B-7.</p>

<p>To support fine tuning, vibrato, slides and so forth in the XM format, effects
modify the note “period” which is not a period but 1/16th of a (negative<sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup>)
semitone.  Also, each sample has a coarse and fine tuning offset which are
added on when we compute the play frequency.</p>

<h2 id="resampling">Resampling</h2>

<p><code>mixChannelIntoBuf</code>’s job is to write a sample played at a certain frequency
onto a buffer which is played at the output frequency, usually 44.1kHz.  It
turns out that playing a sample recorded at a different frequency from the
output frequency is a surprisingly nontrivial problem.</p>

<p>From the <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist-Shannon
theorem</a>,
we know that our original sample only contains frequencies less than or equal
to the original sample rate. So ideally, when we play it back at the new
frequency, the same set of frequencies should be played.</p>

<p>In practice, though, without using a “brick wall” or “sinc” filter, we’re going
to end up with some spurious harmonics due to the aliasing phenomenon. The only
way to avoid that requires a convolution as long as the original sample. In
other words, it’s computationally expensive.</p>

<p>Also, since the original .XM players didn’t do anything fancy, it’s also
typically unnecessary.</p>

<p>It turns out that if we use advanced resampling techniques to eliminate
unwanted alias harmonics, many songs<sup id="fnref:5"><a href="#fn:5" class="footnote">5</a></sup> sound pretty bad. The original
hardware and software that played these either used “zero-order hold” – just
output the sample closest to the interpolated time – or “first-order hold” –
interpolate between the surrounding samples.</p>

<p>I compromised with a very simple implementation that I think sounds pretty
good. I use a combination of zero-order hold and a per-channel two-pole
low-pass filter, which has very low implementation complexity. I will leave the
details for my next post.</p>

<p>Either way, we compute the speed at which we proceed through the sample, which
is the ratio of the playback frequency to the output frequency:</p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kd">function</span> <span class="nx">UpdateChannelPeriod</span><span class="p">(</span><span class="nx">ch</span><span class="p">,</span> <span class="nx">period</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">freq</span> <span class="o">=</span> <span class="mi">8363</span> <span class="o">*</span> <span class="nb">Math</span><span class="p">.</span><span class="nx">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mf">1152.0</span> <span class="o">-</span> <span class="nx">period</span><span class="p">)</span> <span class="o">/</span> <span class="mf">192.0</span><span class="p">);</span>
  <span class="nx">ch</span><span class="p">.</span><span class="nx">doff</span> <span class="o">=</span> <span class="nx">freq</span> <span class="o">/</span> <span class="nx">f_smp</span><span class="p">;</span>
<span class="p">}</span></code></pre></div>

<p>The <code>doff</code> variable is the delta offset per sample. If we are playing at
exactly 44100Hz, then <code>doff</code> is 1, and we are just copying the sample into the
output.</p>

<p>Here’s what zero-order hold looks like, omitting many details of sample looping
or ending:</p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kd">function</span> <span class="nx">mixChannelIntoBuf</span><span class="p">(</span><span class="nx">ch</span><span class="p">,</span> <span class="nx">start</span><span class="p">,</span> <span class="nx">end</span><span class="p">,</span> <span class="nx">dataL</span><span class="p">,</span> <span class="nx">dataR</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">samp</span> <span class="o">=</span> <span class="nx">ch</span><span class="p">.</span><span class="nx">sample</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="nx">start</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">end</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Dumb javascript tricks:</span>
    <span class="c1">// we use a bitwise OR with 0 to truncate offset to integer</span>
    <span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="nx">samp</span><span class="p">[</span><span class="mi">0</span><span class="o">|</span><span class="nx">ch</span><span class="p">.</span><span class="nx">off</span><span class="p">];</span>

    <span class="nx">ch</span><span class="p">.</span><span class="nx">off</span> <span class="o">+=</span> <span class="nx">ch</span><span class="p">.</span><span class="nx">doff</span><span class="p">;</span>
    <span class="nx">dataL</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span> <span class="o">+=</span> <span class="nx">ch</span><span class="p">.</span><span class="nx">volL</span> <span class="o">*</span> <span class="nx">s</span><span class="p">;</span>  <span class="c1">// multiply by left volume</span>
    <span class="nx">dataR</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span> <span class="o">+=</span> <span class="nx">ch</span><span class="p">.</span><span class="nx">volR</span> <span class="o">*</span> <span class="nx">s</span><span class="p">;</span>  <span class="c1">// and right volume</span>
    <span class="k">if</span> <span class="p">(</span><span class="nx">ch</span><span class="p">.</span><span class="nx">off</span> <span class="o">&gt;=</span> <span class="nx">ch</span><span class="p">.</span><span class="nx">sample</span><span class="p">.</span><span class="nx">length</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">if</span> <span class="p">(</span><span class="nx">ch</span><span class="p">.</span><span class="nx">sample</span><span class="p">.</span><span class="nx">loop</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">ch</span><span class="p">.</span><span class="nx">off</span> <span class="o">-=</span> <span class="nx">ch</span><span class="p">.</span><span class="nx">sample</span><span class="p">.</span><span class="nx">looplen</span><span class="p">;</span>
      <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">return</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></div>

<p>In practice I unroll that loop, compute how many samples I can generate before
the sample ends or loops so I don’t have to test in the inner loop, and also
unroll short sample loops in memory.</p>

<p>The end result runs fast enough to play without hitches on my phone.</p>

<p>The main problem with zero-order hold is that it produces hard edges between
samples, and so there are a lot of high pitched hisses and noise. As a result,
I added an additional low-pass filter to each channel with a cutoff equal to
half the playback sampling frequency. My next blog post will go into detail.</p>

<h2 id="synchronized-visualizations">Synchronized visualizations</h2>

<p>It might seem reasonable that in order to show what’s happening on the screen
while you’re hearing it, you need to use a really small buffer so that the
latency between when we compute a sound buffer and when it plays is minimized.
The problem with that is on a webpage, a low latency buffer can mean choppy
audio as the browser might have better things to do than call your javascript
audio callback within 20 milliseconds. It’s pretty far from a realtime system.</p>

<p>But we actually don’t care about latency at all; there are no external events
changing the sound in an unpredictable way (other than pausing, which is
handled separately). The code on this page is using a callback buffer size of
16384, over 300 milliseconds, and yet the oscilloscopes and patterns are
updating at roughly the tick rate (~50Hz). How does that work?</p>

<p>Whenever I finish rendering a tick to the audio buffer, I push a visualization
state onto a queue, keyed by the current <em>audio time</em> in samples.
<code>AudioContext</code> has a <code>currentTime</code> attribute, which is the number of seconds
that audio has been playing since the context was created. On my audio
callback, I capture this and then add <code>offset / f_smp</code> to the time for each
tick. And then I push the first few samples of each channel, plus the current
pattern and current row, onto a queue. My rendering code just compares
<code>audioctx.currentTime</code> against the head of the queue and renders what comes
next.</p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kd">function</span> <span class="nx">redrawScreen</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">audio_events</span><span class="p">.</span><span class="nx">length</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
  <span class="kd">var</span> <span class="nx">e</span><span class="p">;</span>
  <span class="kd">var</span> <span class="nx">t</span> <span class="o">=</span> <span class="nx">audioctx</span><span class="p">.</span><span class="nx">currentTime</span><span class="p">;</span>
  <span class="k">do</span> <span class="p">{</span>
    <span class="nx">e</span> <span class="o">=</span> <span class="nx">audio_events</span><span class="p">.</span><span class="nx">shift</span><span class="p">();</span>
  <span class="p">}</span> <span class="k">while</span><span class="p">(</span><span class="nx">e</span><span class="p">.</span><span class="nx">t</span> <span class="o">&lt;</span> <span class="nx">t</span> <span class="o">&amp;&amp;</span> <span class="nx">audio_events</span><span class="p">.</span><span class="nx">length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">e</span> <span class="o">==</span> <span class="kc">undefined</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>

  <span class="c1">// draw VU meters, oscilloscopes, and update pattern position</span>
  <span class="c1">// using various 2D canvas calls</span>
<span class="p">}</span></code></pre></div>

<p>The patterns are rendered by calling <code>drawImage</code> on individual letters from
<a href="/code/jsxm/ft2font.png">the original font image</a> onto an off-screen canvas
every time a new pattern is to be shown, and then compositing that canvas onto
the screen above in order to highlight the currently-playing row.</p>

<h2 id="end-result">End result</h2>

<p>The player is also available <a href="/code/jsxm/">here</a> without the accompanying
article. By the way, you can load arbitrary XMs on the web by using an anchor
with a link, e.g. http://www.a1k0n.net/code/jsxm/#http://your.host.here/blah.xm
– but only if the host sets a CORS (<code>Access-Control-Allow-Origin</code>) header.</p>

<p>I think what was most fun about playing .MODs and their ilk back in days of
yore was that you could actually <em>see</em> how a complex piece of music is put
together, and watch your computer perform it live. I wanted to recreate that
experience.  There are other web-based .MOD players now, like
<a href="http://mod.haxor.fi">mod.haxor.fi</a>, but I wanted to write my own just for fun.</p>

<p>It was fun. Though it isn’t complete effects-wise, I couldn’t be happier with
how it turned out.</p>

<h3 id="footnotes">Footnotes</h3>

<!--
 - background
   - first thing i heard on a soundblaster, music you can see
   - chiptunes
   - amiga paula, .MOD format - assembly language for music
   - ProTracker, FastTracker 2, ScreamTracker 3 (S3M), Impulse Tracker,
     MilkyTracker, ...
   - kamel.xm ripped from ...? youtube link?

 - .XM format: multi-sample instruments, envelopes
   - great for chiptunes
   - XM documentation mostly wrong

 - basics: note, inst, vol, effect
   - "tempo" / "bpm" -> "row", "ticks"
   - effects, some on tick 0, some "between rows"

 - HTML5 AudioContext
   - ScriptNode callback
   - architecture: render a tick at a time, a channel at a time, a sample loop at a time
     - fast inner loop
   - time synchronization w/ audioContext.currentTime

 - resampling: playing 8363Hz sample at @44100Hz output
   - naive integer truncation (zero order hold)
   - linear
   - FFT resampling
   - brickwall; lanczos; etc; ... too much effort
   - cheap IIR LPF

-->
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>The one exception being when the sample ends during the tick. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>I’ve omitted the details of stereo, but we sum up the left and right channels independently. Panning is just a different volume on the left channel vs. the right channel. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><code>Array.fill()</code> is not available in all browsers, so in practice I use a for loop to clear the buffer. And the buffer is <em>not</em> already cleared when it is passed to us; it may actually contain data from the previous callback. <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p>For historical reasons I won’t go into here, .MOD effects modified the sample <em>period</em>, or inverse frequency, as making linear changes to it sounds more linear to the ear; but really, it’s an approximation of the logarithmic scale the human ear actually hears. A log scale is used in .XM. So when we increment period in XM, we are stepping down 1/16th of a semitone. <a href="#fnref:4" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p>Especially “chiptunes” – songs with tiny looping square wave or triangle wave samples, to emulate simple vintage sound hardware chips. <a href="#fnref:5" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

</article>







      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <a href="/" class="site-title">a1k0n.net</a>
  </div>
</footer>

</body>
</html>
